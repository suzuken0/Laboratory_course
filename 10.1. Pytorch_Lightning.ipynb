{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMVta2HYBVCxSGmN7IIK2WC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/Laboratory_course/blob/master/10.1.%20Pytorch_Lightning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**画像のスクレイピング --> Lightning Pytorchで分類**\n",
        "\n"
      ],
      "metadata": {
        "id": "25UMQJsL7UPF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**iCrawlerを用いてスクレイピング**\n",
        "\n",
        "https://atmarkit.itmedia.co.jp/ait/articles/2010/28/news018.html\n",
        "\n",
        "公式： https://icrawler.readthedocs.io/en/latest/builtin.html"
      ],
      "metadata": {
        "id": "iMH1ZVOtriop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install icrawler\n",
        "from icrawler.builtin import BingImageCrawler\n",
        "import os\n",
        "\n",
        "# List of keywords\n",
        "keywords = [\"cat\", \"dog\"]\n",
        "max_num = 150\n",
        "\n",
        "for keyword in keywords:\n",
        "    output_dir = f\"/content/{keyword}\"\n",
        "\n",
        "    # Create the directory if it doesn't exist\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    crawler = BingImageCrawler(storage={\"root_dir\": output_dir})\n",
        "    crawler.crawl(keyword=keyword, max_num=max_num)"
      ],
      "metadata": {
        "id": "xfZC5Uv_r87o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Classify dog/cat using Pytorch Lightning**\n",
        "\n",
        "https://tech.aru-zakki.com/from-pytorch-to-lightning/"
      ],
      "metadata": {
        "id": "539gH-qvrOrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import math\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "except ModuleNotFoundError:\n",
        "    !pip install japanize_matplotlib\n",
        "    import japanize_matplotlib\n",
        "import numpy as np\n",
        "import time\n",
        "import copy\n",
        "import requests\n",
        "from PIL import Image\n",
        "from types import SimpleNamespace\n",
        "from io import StringIO\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "\n",
        "def set_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        # GPUありの場合\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def get_device():\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda:0\")\n",
        "    # PytorchLightningでエラーが出るので、MPSはパス\n",
        "    #elif torch.backends.mps.is_built():\n",
        "    #    device = torch.device(\"mps:0\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "    return device"
      ],
      "metadata": {
        "id": "gI3o9qmaTuSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################\n",
        "# 画像をフォルダ整理  #\n",
        "#################\n",
        "\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 画像のパスを取得\n",
        "dog_paths = ['/content/dog/' + f for f in os.listdir('/content/dog/')]\n",
        "cat_paths = ['/content/cat/' + f for f in os.listdir('/content/cat/')]\n",
        "\n",
        "# 画像パスを結合\n",
        "all_paths = dog_paths + cat_paths\n",
        "\n",
        "# 訓練用と検証用に分割\n",
        "train_paths, valid_paths = train_test_split(all_paths, test_size=0.2, random_state=42)\n",
        "\n",
        "# ディレクトリを作成\n",
        "def create_or_clean_dir(directory_path):\n",
        "    if os.path.exists(directory_path):\n",
        "        shutil.rmtree(directory_path)\n",
        "    os.makedirs(directory_path)\n",
        "create_or_clean_dir('/content/train/dog')\n",
        "create_or_clean_dir('/content/train/cat')\n",
        "create_or_clean_dir('/content/valid/dog')\n",
        "create_or_clean_dir('/content/valid/cat')\n",
        "\n",
        "# 画像をコピー\n",
        "for path in train_paths:\n",
        "  if 'dog' in path:\n",
        "    shutil.copy(path, '/content/train/dog')\n",
        "  elif 'cat' in path:\n",
        "    shutil.copy(path, '/content/train/cat')\n",
        "\n",
        "for path in valid_paths:\n",
        "  if 'dog' in path:\n",
        "    shutil.copy(path, '/content/valid/dog')\n",
        "  elif 'cat' in path:\n",
        "    shutil.copy(path, '/content/valid/cat')"
      ],
      "metadata": {
        "id": "onUCaQRv_gsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "ODEn0pD_Cctg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import loggers as pl_loggers\n",
        "from pytorch_lightning.callbacks import ProgressBar, LearningRateMonitor\n",
        "from pytorch_lightning.core.datamodule import LightningDataModule\n",
        "import torch.nn.functional as F\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "class CatDogDataModule(LightningDataModule):\n",
        "    # コンストラクタでバッチサイズを初期化します。\n",
        "    def __init__(self, batch_size=32):\n",
        "      super().__init__()\n",
        "      self.batch_size = batch_size\n",
        "      # データ前処理のための変換を定義します。\n",
        "      self.data_transform = transforms.Compose([\n",
        "        transforms.Resize(256), # 画像を256x256にリサイズ\n",
        "        transforms.CenterCrop(224), # 中心で224x224にクロップ\n",
        "        transforms.ToTensor(), # 画像をテンソルに変換\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # 標準化\n",
        "      ])\n",
        "\n",
        "    # データセットをセットアップします。'fit'ステージまたはデフォルトで実行されます。\n",
        "    def setup(self, stage=None):\n",
        "      if stage == 'fit' or stage is None:\n",
        "        # 訓練データセットを定義します。\n",
        "        self.train_dataset = ImageFolder(root='/content/train', transform=self.data_transform)\n",
        "        # 検証データセットを定義します。\n",
        "        self.valid_dataset = ImageFolder(root='/content/valid', transform=self.data_transform)\n",
        "\n",
        "    # 訓練データローダーを作成します。\n",
        "    def train_dataloader(self):\n",
        "      return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    # 検証データローダーを作成します。\n",
        "    def val_dataloader(self):\n",
        "      return DataLoader(self.valid_dataset, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "class Classifier(pl.LightningModule):\n",
        "    # モデルを初期化します。\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      # ResNet50モデルを読み込み、事前訓練された重みを使用します。\n",
        "      self.model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
        "      # 最後の全結合層を2クラス分類用に置き換えます。\n",
        "      self.model.fc = torch.nn.Linear(self.model.fc.in_features, 2)\n",
        "\n",
        "    # 順伝播を定義します。\n",
        "    def forward(self, x):\n",
        "      return self.model(x)\n",
        "\n",
        "    # 訓練ステップを定義します。\n",
        "    def training_step(self, batch, batch_idx):\n",
        "      x, y = batch\n",
        "      y_hat = self(x)\n",
        "      loss = F.cross_entropy(y_hat, y)\n",
        "\n",
        "      preds = torch.argmax(y_hat, dim=1)\n",
        "      acc = (preds == y).float().mean()\n",
        "\n",
        "      # 訓練の損失と正確さをログに記録します。\n",
        "      self.log('train_loss', loss, prog_bar=True)\n",
        "      self.log('train_acc', acc, prog_bar=True)\n",
        "\n",
        "      return loss\n",
        "\n",
        "    # 検証ステップを定義します。\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "      x, y = batch\n",
        "      y_hat = self(x)\n",
        "      loss = F.cross_entropy(y_hat, y)\n",
        "\n",
        "      preds = torch.argmax(y_hat, dim=1)\n",
        "      acc = (preds == y).float().mean()\n",
        "\n",
        "      # 検証の損失と正確さをログに記録します。\n",
        "      self.log('val_loss', loss, prog_bar=True)\n",
        "      self.log('val_acc', acc, prog_bar=True)\n",
        "\n",
        "    # オプティマイザーを設定します。\n",
        "    def configure_optimizers(self):\n",
        "      return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "\n",
        "\n",
        "class PrintMetricsCallback(pl.Callback):\n",
        "    # 訓練のエポックが終わる度にメトリクスを印刷します。\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        # 訓練エポックにおけるログに記録されたメトリクスを取得して印刷します。\n",
        "        metrics = trainer.logged_metrics\n",
        "        print(f\"Epoch: {trainer.current_epoch}, Train Loss: {metrics['train_loss'].item():.4f}, Train Acc: {metrics['train_acc'].item():.4f}\")\n",
        "\n",
        "    # 検証のエポックが終わる度にメトリクスを印刷します。\n",
        "    def on_validation_epoch_end(self, trainer, pl_module):\n",
        "        # 検証エポックにおけるログに記録されたメトリクスを取得して印刷します。\n",
        "        metrics = trainer.logged_metrics\n",
        "        print(f\"\\nEpoch: {trainer.current_epoch}, Validation Loss: {metrics['val_loss'].item():.4f}, Validation Acc: {metrics['val_acc'].item():.4f}\")\n",
        "\n",
        "# データモジュールを初期化します（バッチサイズ32）。\n",
        "data_module = CatDogDataModule(batch_size=32)\n",
        "# 分類器モデルを初期化します。\n",
        "model = Classifier()\n",
        "\n",
        "# TensorBoardでログを記録するためのロガーを初期化します。\n",
        "logger = pl_loggers.TensorBoardLogger('logs/')\n",
        "\n",
        "# トレーナーオブジェクトを初期化します。\n",
        "trainer = pl.Trainer(\n",
        "  max_epochs=3, # 最大エポック数を設定します。\n",
        "  accelerator='gpu', # GPUを使用するように設定します。\n",
        "  devices=1, # 使用するデバイスの数（GPUの数）を設定します。\n",
        "  callbacks=[PrintMetricsCallback()], # コールバックを追加します。\n",
        "  logger=logger  # ロガーを設定します。\n",
        ")\n",
        "\n",
        "# 訓練を開始します。\n",
        "trainer.fit(model, datamodule=data_module)\n"
      ],
      "metadata": {
        "id": "-i0QAUcdTuWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import torch\n",
        "from torchvision.utils import make_grid\n",
        "from PIL import Image\n",
        "\n",
        "# モデルを評価モードに設定\n",
        "model.eval()\n",
        "\n",
        "# 画像の視覚化のための逆変換を定義します\n",
        "inverse_transform = transforms.Compose([\n",
        "    transforms.Normalize(mean=[0., 0., 0.], std=[1/0.229, 1/0.224, 1/0.225]),\n",
        "    transforms.Normalize(mean=[-0.485, -0.456, -0.406], std=[1., 1., 1.]),\n",
        "])\n",
        "\n",
        "# trainer.fit(model, datamodule=data_module) が既に実行されていると仮定します\n",
        "valid_dataset = data_module.valid_dataset\n",
        "# 検証データセットからランダムに30個のインデックスを選択\n",
        "indices = random.sample(range(len(valid_dataset)), 30)\n",
        "\n",
        "# 選択した画像とその予測結果を視覚化します\n",
        "for i in indices:\n",
        "    # 生の画像へのパスとラベルを取得\n",
        "    path, y = valid_dataset.imgs[i]\n",
        "\n",
        "    # 画像ファイルをPIL Imageとして開く\n",
        "    x_raw = Image.open(path).convert('RGB')\n",
        "\n",
        "    # 元の変換パイプラインを適用\n",
        "    x_transformed = data_module.data_transform(x_raw).unsqueeze(0)  # バッチ次元を追加\n",
        "\n",
        "    # 予測を実行\n",
        "    y_hat = model(x_transformed)\n",
        "    pred = torch.argmax(y_hat, dim=1)\n",
        "\n",
        "    # 画像のインデックス、実際のラベル、予測ラベルを表示\n",
        "    print(f\"Image: {i}\")\n",
        "    print(f\"Label: {y}\")\n",
        "    print(f\"Prediction: {pred.item()}\")\n",
        "\n",
        "    # 視覚化のために逆変換を適用\n",
        "    x_vis = inverse_transform(x_transformed.squeeze())  # バッチ次元を削除\n",
        "\n",
        "    # テンソルを画像に変換して表示\n",
        "    plt.imshow(x_vis.permute(1, 2, 0).numpy())  # テンソルを画像フォーマットに変更\n",
        "    plt.axis('off')  # 軸をオフにする\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "i7o5mRJFfRiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c433Ngln4n_i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}